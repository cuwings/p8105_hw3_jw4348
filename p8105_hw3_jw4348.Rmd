---
title: "p8105_hw3_jw4348"
author: "Jingyu Wang"
output: github_document
date: "2023-10-12"
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)

library(p8105.datasets)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Question 1

- Description of the dataset `instacart`:
This dataset contains **`r nrow(instacart)`** rows and **`r ncol(instacart)`** columns, with each row resprenting a single product from an instacart order. Variables include **identifiers for user, order, and product; the order in which each product was added to the cart**. There are several order-level variables, describing the day and time of the order, and number of days since prior order. Then there are several item-specific variables, describing the product name (e.g. Yogurt, Avocado), department (e.g. dairy and eggs, produce), and aisle (e.g. yogurt, fresh fruits), and whether the item has been ordered by this user in the past. In total, there are **`r instacart |> select(product_id) |> distinct() |> count()`** products found in **`r instacart |> select(user_id, order_id) |> distinct() |> count()`** orders from **`r instacart |> select(user_id) |> distinct() |> count()`** distinct users.

- A table summarizing the aisle.

```{r}
instacart |> 
  count(aisle) |> 
  arrange(desc(n))
```

- Based on the output, there are **134** aisles, with **fresh vegetables** and **fresh fruits** holding the most items ordered by far, which are **150609** items and **150473** items.

- Next is the plot of number of items ordered in each aisle.

```{r}
instacart |> 
  count(aisle) |> 
  filter(n > 10000) |> 
  mutate(aisle = fct_reorder(aisle, n)) |> 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

```

- Next is a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”.

```{r}
instacart |> 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |>
  group_by(aisle) |> 
  count(product_name) |> 
  mutate(rank = min_rank(desc(n))) |> 
  filter(rank < 4) |> 
  arrange(desc(n)) |>
  knitr::kable()
```

- Finally is a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.

```{r}
instacart |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  group_by(product_name, order_dow) |>
  summarize(mean_hour = mean(order_hour_of_day)) |>
  pivot_wider(
    names_from = order_dow, 
    values_from = mean_hour) |>
  knitr::kable(digits = 2)
```

## Question 2

#### First I did some data cleaning:

```{r}
brfss_df = brfss_smart2010 |> 
  janitor::clean_names() |> 
  rename(states = locationabbr, locations = locationdesc) |>
  filter(topic == "Overall Health", 
         response == "Excellent" | response == "Very good" |response == "Good" | response == "Fair" | response == "Poor" ) |>
  mutate(
        response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"))
        )
```

#### Then I will create a dataframe for 2002 and 2010:

```{r}
brfss_2002_df = brfss_df |> 
  filter(year == 2002) |>
  group_by(states) |> 
  count(locations)|>
  distinct() |> 
  filter(n() >= 7) |> 
  select(states) |> 
  distinct()

brfss_2010_df = brfss_df |> 
  filter(year == 2010) |>
  group_by(states) |> 
  count(locations)|>
  distinct() |> 
  filter(n() >= 7) |> 
  select(states) |> 
  distinct() 
```

- In 2002, states **`r pull(brfss_2002_df, states)`** were observed at 7 or more locations. In 2010, **`r pull(brfss_2010_df, states)`** were observed at 7 or more locations.

#### Next I construct a new dataset with some requirement, and then I make a plot of the average value over time for each states in some requirement:

```{r}
brfss_excellent_df = brfss_df |> 
  select(states, response, data_value, year) |> 
  filter(response == "Excellent") |> 
  group_by(states, year) |> 
  summarize (
    mean_value = mean(data_value, na.rm = TRUE)
  )

  ggplot(brfss_excellent_df, aes(x = year, y = mean_value)) +
    geom_line(aes(color = states), alpha = .5) +
    labs(title = " Average value across years among states in the United States",
         x = "Year",
         y = "Mean value") +
    theme(legend.position = "right")
```

* For the dataset that is limited to **Excellent** responses, there are **`r nrow(brfss_excellent_df)`** rows and **`r ncol(brfss_excellent_df)`** columns.
* This plot showed the average value over years for each states who only response `Excellent`.
  * Most state have their average values of `Excellent` response between **17 to 27**. 
  * All of the average value are **bumping up and down** across the years.

#### Next I will make a two-panel plot showing distribution of **data_value** for responses in years **2006** and **2010**:

```{r}
brfss_ny_df = brfss_df |>
  filter (states == "NY",
          year == 2006 | year == 2010)

ggplot(brfss_ny_df, aes(x=data_value, fill=response)) +
  geom_density(alpha = 0.5) +
  labs(title = "Distribution of responses in NY state in year of 2006 and 2010") +
  facet_grid (.~year)
```

* This two panel plot showed distribution of value for all responses in year 2006 and 2010.
  * In **both 2006 and 2010**, people have **least** response of **poor** and **second least** response of **fair**. **Most** response are **above fair**. And, the **most** response is **very good**. 
  * We have **more** people responded **excellent and good** in **2010** than 2006.